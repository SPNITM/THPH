{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3829fd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.fftpack import dct\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87c18a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions for video processing\n",
    "def open_video(video_path):\n",
    "    return cv2.VideoCapture(video_path)\n",
    "\n",
    "def save_video(output_path, fps, frame_size, is_color=True):\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    return cv2.VideoWriter(output_path, fourcc, fps, frame_size, is_color)\n",
    "\n",
    "def process_and_save_video(video_path, output_path, process_func, is_color=True):\n",
    "    cap = open_video(video_path)\n",
    "    out = save_video(output_path, cap.get(cv2.CAP_PROP_FPS),\n",
    "                     (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))), is_color)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        processed_frame = process_func(frame)\n",
    "        out.write(processed_frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b41564b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation and Filter functions\n",
    "def apply_gaussian_blur(frame, kernel_size=(5, 5)):\n",
    "    return cv2.GaussianBlur(frame, kernel_size, 0)\n",
    "\n",
    "def apply_sharpening(frame):\n",
    "    kernel = np.array([[0, -1, 0],\n",
    "                       [-1, 5, -1],\n",
    "                       [0, -1, 0]])\n",
    "    return cv2.filter2D(frame, -1, kernel)\n",
    "\n",
    "def apply_smoothing(frame, diameter=15, sigma_color=75, sigma_space=75):\n",
    "    return cv2.bilateralFilter(frame, diameter, sigma_color, sigma_space)\n",
    "\n",
    "def apply_edge_detection(frame):\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    edges = cv2.Canny(gray_frame, 100, 200)\n",
    "    return cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "def apply_color_filtering(frame, lower_bound=(35, 50, 50), upper_bound=(85, 255, 255)):\n",
    "    hsv_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    mask = cv2.inRange(hsv_frame, lower_bound, upper_bound)\n",
    "    return cv2.bitwise_and(frame, frame, mask=mask)\n",
    "\n",
    "def apply_compression(frame, quality=30):\n",
    "    encode_param = [int(cv2.IMWRITE_JPEG_QUALITY), quality]\n",
    "    result, encimg = cv2.imencode('.jpg', frame, encode_param)\n",
    "    return cv2.imdecode(encimg, 1)\n",
    "\n",
    "def apply_rotation(video_path, output_path, angle=90):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Adjust frame dimensions for 90° or 270° rotation\n",
    "    if angle in [90, 270]:\n",
    "        new_width, new_height = height, width\n",
    "    else:\n",
    "        new_width, new_height = width, height\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (new_width, new_height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if angle == 90:\n",
    "            rotated_frame = cv2.rotate(frame, cv2.ROTATE_90_CLOCKWISE)\n",
    "        elif angle == 180:\n",
    "            rotated_frame = cv2.rotate(frame, cv2.ROTATE_180)\n",
    "        elif angle == 270:\n",
    "            rotated_frame = cv2.rotate(frame, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "        else:\n",
    "            rotated_frame = frame\n",
    "\n",
    "        out.write(rotated_frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "def apply_scaling(video_path, output_path, new_size=(320, 240)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), new_size)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        resized_frame = cv2.resize(frame, new_size)\n",
    "        out.write(resized_frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "def apply_cropping(video_path, output_path, crop_rect=(50, 50, 200, 200)):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "\n",
    "    crop_width = crop_rect[2]\n",
    "    crop_height = crop_rect[3]\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (crop_width, crop_height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        cropped_frame = frame[crop_rect[1]:crop_rect[1] + crop_rect[3], crop_rect[0]:crop_rect[0] + crop_rect[2]]\n",
    "        out.write(cropped_frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "def loop_video(input_path, output_path, loop_count=3):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "    frames = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frames.append(frame)\n",
    "\n",
    "    cap.release()\n",
    "\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    for _ in range(loop_count):\n",
    "        for frame in frames:\n",
    "            out.write(frame)\n",
    "\n",
    "    out.release()\n",
    "\n",
    "def apply_translation(video_path, output_path, tx=30, ty=30):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    out = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (width, height))\n",
    "\n",
    "    # Define translation matrix\n",
    "    M = np.float32([[1, 0, tx], [0, 1, ty]])\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Apply the translation\n",
    "        translated_frame = cv2.warpAffine(frame, M, (width, height))\n",
    "        out.write(translated_frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "def apply_zoom(video_path, output_path, zoom_factor=1.5):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    out = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (width, height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Calculate center crop dimensions\n",
    "        center_x, center_y = width // 2, height // 2\n",
    "        crop_width, crop_height = int(width / zoom_factor), int(height / zoom_factor)\n",
    "        crop_x1 = max(0, center_x - crop_width // 2)\n",
    "        crop_x2 = min(width, center_x + crop_width // 2)\n",
    "        crop_y1 = max(0, center_y - crop_height // 2)\n",
    "        crop_y2 = min(height, center_y + crop_height // 2)\n",
    "\n",
    "        # Crop and resize to original size\n",
    "        cropped_frame = frame[crop_y1:crop_y2, crop_x1:crop_x2]\n",
    "        zoomed_frame = cv2.resize(cropped_frame, (width, height))\n",
    "\n",
    "        out.write(zoomed_frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "def apply_affine_transformation(video_path, output_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    out = cv2.VideoWriter(output_path, fourcc, cap.get(cv2.CAP_PROP_FPS), (width, height))\n",
    "\n",
    "    # Define affine transformation matrix\n",
    "    pts1 = np.float32([[50, 50], [200, 50], [50, 200]])\n",
    "    pts2 = np.float32([[10, 100], [200, 50], [100, 250]])\n",
    "    M = cv2.getAffineTransform(pts1, pts2)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Apply the affine transformation\n",
    "        affine_transformed_frame = cv2.warpAffine(frame, M, (width, height))\n",
    "        out.write(affine_transformed_frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "def apply_perspective_transformation(video_path, output_path):\n",
    "    cap = open_video(video_path)\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = save_video(output_path, cap.get(cv2.CAP_PROP_FPS), (width, height))\n",
    "\n",
    "    # Define points for perspective transformation\n",
    "    pts1 = np.float32([[0, 0], [width - 1, 0], [0, height - 1], [width - 1, height - 1]])\n",
    "    pts2 = np.float32([[0, 0], [width - 100, 50], [50, height - 50], [width - 50, height - 100]])\n",
    "    M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Apply perspective transformation\n",
    "        perspective_frame = cv2.warpPerspective(frame, M, (width, height))\n",
    "        out.write(perspective_frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "def apply_frame_dropping(input_path, output_path, drop_rate):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) / drop_rate\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    frame_count = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        if frame_count % drop_rate == 0:\n",
    "            out.write(frame)\n",
    "        frame_count += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "def apply_frame_rate_conversion(input_path, output_path, new_fps):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    out = cv2.VideoWriter(output_path, fourcc, new_fps, (width, height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "\n",
    "def apply_speed_manipulation(input_path, output_path, speed_factor):\n",
    "    cap = cv2.VideoCapture(input_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) * speed_factor\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        out.write(frame)\n",
    "\n",
    "    cap.release()\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e892c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hashing functions\n",
    "def phash(frame):\n",
    "    pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    return str(imagehash.phash(pil_image))\n",
    "\n",
    "def whash(frame):\n",
    "    pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    return str(imagehash.whash(pil_image))\n",
    "\n",
    "def ahash(frame):\n",
    "    pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    return str(imagehash.average_hash(pil_image))\n",
    "\n",
    "def dhash(frame):\n",
    "    pil_image = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "    return str(imagehash.dhash(pil_image))\n",
    "\n",
    "def kl_hash(frame, hash_size=8):\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    resized_frame = cv2.resize(gray_frame, (64, 64), interpolation=cv2.INTER_LANCZOS4)\n",
    "    pixels = resized_frame.astype(float)\n",
    "\n",
    "    pca = PCA(n_components=hash_size)\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "        pca_transformed = pca.fit_transform(pixels)\n",
    "\n",
    "    if np.isnan(pca_transformed).any():\n",
    "        pca_transformed = np.nan_to_num(pca_transformed)\n",
    "\n",
    "    dct_transformed = dct(dct(pca_transformed, axis=0), axis=1)\n",
    "    dct_low_freq = dct_transformed[:hash_size, :hash_size]\n",
    "    dct_median_val = np.median(dct_low_freq)\n",
    "    dct_hash_array = (dct_low_freq > dct_median_val).astype(int)\n",
    "    dct_hash_string = ''.join(str(x) for x in dct_hash_array.flatten())\n",
    "    dct_hash_hex = hex(int(dct_hash_string, 2))[2:].zfill(hash_size * hash_size // 4)\n",
    "\n",
    "    return dct_hash_hex\n",
    "\n",
    "# Function to process and compute hashes for video frames\n",
    "def process_video_and_compute_hashes(video_path, hash_func):\n",
    "    cap = open_video(video_path)\n",
    "    video_hashes = []\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_hash = hash_func(frame)\n",
    "        video_hashes.append(frame_hash)\n",
    "\n",
    "    cap.release()\n",
    "    return video_hashes\n",
    "\n",
    "# Similarity calculation functions\n",
    "def hex_to_bin(hex_str):\n",
    "    return bin(int(hex_str, 16))[2:].zfill(256)\n",
    "\n",
    "def hamming_distance(bin_str1, bin_str2):\n",
    "    return sum(c1 != c2 for c1, c2 in zip(bin_str1, bin_str2))\n",
    "\n",
    "def similarity_score(original_hashes, edited_hashes):\n",
    "    scores = []\n",
    "    for original, edited in zip(original_hashes, edited_hashes):\n",
    "        bin_original = hex_to_bin(original)\n",
    "        bin_edited = hex_to_bin(edited)\n",
    "        distance = hamming_distance(bin_original, bin_edited)\n",
    "        score = 1 - (distance / len(bin_original))\n",
    "        scores.append(score)\n",
    "    return scores\n",
    "\n",
    "def compute_similarity_scores(original_hashes, modified_hashes):\n",
    "    if not original_hashes or not modified_hashes:\n",
    "        print(\"Error: One or both sets of hashes are empty.\")\n",
    "        return [], 0.0\n",
    "\n",
    "    if len(original_hashes) != len(modified_hashes):\n",
    "        print(\"Warning: The number of hashes in the original and modified videos do not match.\")\n",
    "        return [], 0.0\n",
    "\n",
    "    scores = similarity_score(original_hashes, modified_hashes)\n",
    "    average_score = sum(scores) / len(scores) if scores else 0.0\n",
    "    return scores, average_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f02673e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage for computing different hashes and transformations\n",
    "video_path = r\"C:\\Users\\prias\\Downloads\\THPH\\CGI Animated Short Film_ _Watermelon A Cautionary Tale_ by Kefei Li & Connie Qin He _ CGMeetup.mp4\"\n",
    "transformations = {\n",
    "    'Blurred': (apply_gaussian_blur, 'blurred_video.mp4'),\n",
    "    'Sharpened': (apply_sharpening, 'sharpened_video.mp4'),\n",
    "    'Smoothed': (apply_smoothing, 'smoothed_video.mp4'),\n",
    "    'Edges': (apply_edge_detection, 'edges_video.mp4'),\n",
    "    'Color Filtered': (apply_color_filtering, 'color_filtered_video.mp4'),\n",
    "    'Compressed': (lambda frame: apply_compression(frame, quality=30), 'compressed_video.mp4'),\n",
    "    'Rotated': (lambda video, out: apply_rotation(video, out, angle=90), 'rotated_video_90.mp4'),\n",
    "    'Resized': (lambda video, out: apply_scaling(video, out, new_size=(320, 240)), 'resized_video.mp4'),\n",
    "    'Cropped': (lambda video, out: apply_cropping(video, out, crop_rect=(50, 50, 200, 200)), 'cropped_video.mp4'),\n",
    "    'Flipped Horizontal': (lambda frame: cv2.flip(frame, 1), 'flipped_video_horizontal.mp4'),\n",
    "    'Flipped Vertical': (lambda frame: cv2.flip(frame, 0), 'flipped_video_vertical.mp4'),\n",
    "    'Translated': (lambda video, out: apply_translation(video, out, tx=30, ty=30), 'translated_video.mp4'),\n",
    "    'Zoomed': (lambda video, out: apply_zoom(video, out, zoom_factor=1.5), 'zoomed_video.mp4'),\n",
    "    'Affine Transformed': (apply_affine_transformation, 'affine_transformed_video.mp4'),\n",
    "    'Perspective Transformed': (apply_perspective_transformation, 'perspective_transformed_video.mp4'),\n",
    "    'Frame Dropped': (lambda video, out: apply_frame_dropping(video, out, drop_rate=2), 'frame_dropped_video.mp4'),\n",
    "    'Frame Rate Converted': (lambda video, out: apply_frame_rate_conversion(video, out, new_fps=15), 'frame_rate_converted_video.mp4'),\n",
    "    'Slowed Down': (lambda video, out: apply_speed_manipulation(video, out, speed_factor=0.5), 'slowed_down_video.mp4'),\n",
    "    'Looped': (lambda video, out: loop_video(video, out, loop_count=3), 'looped_video.mp4')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a742a7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the hashes for the original video\n",
    "original_hashes = {\n",
    "    'pHash': process_video_and_compute_hashes(video_path, phash),\n",
    "    'wHash': process_video_and_compute_hashes(video_path, whash),\n",
    "    'aHash': process_video_and_compute_hashes(video_path, ahash),\n",
    "    'dHash': process_video_and_compute_hashes(video_path, dhash),\n",
    "    'KL Hash': process_video_and_compute_hashes(video_path, kl_hash)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b7258a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Blurred transformation...\n",
      "Comparing original and Blurred pHash hashes:\n",
      "Average Blurred pHash Similarity: 0.998849852071006\n",
      "Comparing original and Blurred wHash hashes:\n",
      "Average Blurred wHash Similarity: 0.9972670118343195\n",
      "Comparing original and Blurred aHash hashes:\n",
      "Average Blurred aHash Similarity: 0.999060650887574\n",
      "Comparing original and Blurred dHash hashes:\n",
      "Average Blurred dHash Similarity: 0.9984291789940828\n",
      "Comparing original and Blurred KL Hash hashes:\n",
      "Average Blurred KL Hash Similarity: 0.9712629437869823\n",
      "Applying Sharpened transformation...\n",
      "Comparing original and Sharpened pHash hashes:\n",
      "Average Sharpened pHash Similarity: 0.9976793639053254\n",
      "Comparing original and Sharpened wHash hashes:\n",
      "Average Sharpened wHash Similarity: 0.9961621671597634\n",
      "Comparing original and Sharpened aHash hashes:\n",
      "Average Sharpened aHash Similarity: 0.998542899408284\n",
      "Comparing original and Sharpened dHash hashes:\n",
      "Average Sharpened dHash Similarity: 0.9974519230769231\n",
      "Comparing original and Sharpened KL Hash hashes:\n",
      "Average Sharpened KL Hash Similarity: 0.9563461538461538\n",
      "Applying Smoothed transformation...\n",
      "Comparing original and Smoothed pHash hashes:\n",
      "Average Smoothed pHash Similarity: 0.9982174556213018\n",
      "Comparing original and Smoothed wHash hashes:\n",
      "Average Smoothed wHash Similarity: 0.9969341715976331\n",
      "Comparing original and Smoothed aHash hashes:\n",
      "Average Smoothed aHash Similarity: 0.9988600221893491\n",
      "Comparing original and Smoothed dHash hashes:\n",
      "Average Smoothed dHash Similarity: 0.9980316198224852\n",
      "Comparing original and Smoothed KL Hash hashes:\n",
      "Average Smoothed KL Hash Similarity: 0.9738757396449704\n",
      "Applying Edges transformation...\n",
      "Comparing original and Edges pHash hashes:\n",
      "Average Edges pHash Similarity: 0.8873705621301775\n",
      "Comparing original and Edges wHash hashes:\n",
      "Average Edges wHash Similarity: 0.8966392381656805\n",
      "Comparing original and Edges aHash hashes:\n",
      "Average Edges aHash Similarity: 0.8956897189349112\n",
      "Comparing original and Edges dHash hashes:\n",
      "Average Edges dHash Similarity: 0.8941660502958579\n",
      "Comparing original and Edges KL Hash hashes:\n",
      "Average Edges KL Hash Similarity: 0.8841050295857988\n",
      "Applying Color Filtered transformation...\n",
      "Comparing original and Color Filtered pHash hashes:\n",
      "Average Color Filtered pHash Similarity: 0.881617973372781\n",
      "Comparing original and Color Filtered wHash hashes:\n",
      "Average Color Filtered wHash Similarity: 0.8833247041420118\n",
      "Comparing original and Color Filtered aHash hashes:\n",
      "Average Color Filtered aHash Similarity: 0.8853208210059171\n",
      "Comparing original and Color Filtered dHash hashes:\n",
      "Average Color Filtered dHash Similarity: 0.8899676405325444\n",
      "Comparing original and Color Filtered KL Hash hashes:\n",
      "Average Color Filtered KL Hash Similarity: 0.8777144970414201\n",
      "Applying Compressed transformation...\n",
      "Comparing original and Compressed pHash hashes:\n",
      "Average Compressed pHash Similarity: 0.9984837278106509\n",
      "Comparing original and Compressed wHash hashes:\n",
      "Average Compressed wHash Similarity: 0.9966161242603551\n",
      "Comparing original and Compressed aHash hashes:\n",
      "Average Compressed aHash Similarity: 0.9987860576923077\n",
      "Comparing original and Compressed dHash hashes:\n",
      "Average Compressed dHash Similarity: 0.9979872411242604\n",
      "Comparing original and Compressed KL Hash hashes:\n",
      "Average Compressed KL Hash Similarity: 0.9778198964497041\n",
      "Applying Rotated transformation...\n",
      "Comparing original and Rotated pHash hashes:\n",
      "Average Rotated pHash Similarity: 0.8814922337278106\n",
      "Comparing original and Rotated wHash hashes:\n",
      "Average Rotated wHash Similarity: 0.8875480769230769\n",
      "Comparing original and Rotated aHash hashes:\n",
      "Average Rotated aHash Similarity: 0.8926932322485207\n",
      "Comparing original and Rotated dHash hashes:\n",
      "Average Rotated dHash Similarity: 0.8917871671597634\n",
      "Comparing original and Rotated KL Hash hashes:\n",
      "Average Rotated KL Hash Similarity: 0.8826090976331361\n",
      "Applying Resized transformation...\n",
      "Comparing original and Resized pHash hashes:\n",
      "Average Resized pHash Similarity: 0.998644600591716\n",
      "Comparing original and Resized wHash hashes:\n",
      "Average Resized wHash Similarity: 0.9967936390532545\n",
      "Comparing original and Resized aHash hashes:\n",
      "Average Resized aHash Similarity: 0.9988785133136094\n",
      "Comparing original and Resized dHash hashes:\n",
      "Average Resized dHash Similarity: 0.9982692307692308\n",
      "Comparing original and Resized KL Hash hashes:\n",
      "Average Resized KL Hash Similarity: 0.9765440088757397\n",
      "Applying Cropped transformation...\n",
      "Comparing original and Cropped pHash hashes:\n",
      "Average Cropped pHash Similarity: 0.885310650887574\n",
      "Comparing original and Cropped wHash hashes:\n",
      "Average Cropped wHash Similarity: 0.8990865384615384\n",
      "Comparing original and Cropped aHash hashes:\n",
      "Average Cropped aHash Similarity: 0.9034254807692308\n",
      "Comparing original and Cropped dHash hashes:\n",
      "Average Cropped dHash Similarity: 0.8840865384615385\n",
      "Comparing original and Cropped KL Hash hashes:\n",
      "Average Cropped KL Hash Similarity: 0.8886538461538461\n",
      "Applying Flipped Horizontal transformation...\n",
      "Comparing original and Flipped Horizontal pHash hashes:\n",
      "Average Flipped Horizontal pHash Similarity: 0.8792048816568048\n",
      "Comparing original and Flipped Horizontal wHash hashes:\n",
      "Average Flipped Horizontal wHash Similarity: 0.8978873890532545\n",
      "Comparing original and Flipped Horizontal aHash hashes:\n",
      "Average Flipped Horizontal aHash Similarity: 0.9051285133136094\n",
      "Comparing original and Flipped Horizontal dHash hashes:\n",
      "Average Flipped Horizontal dHash Similarity: 0.8947198594674556\n",
      "Comparing original and Flipped Horizontal KL Hash hashes:\n",
      "Average Flipped Horizontal KL Hash Similarity: 0.9837906804733728\n",
      "Applying Flipped Vertical transformation...\n",
      "Comparing original and Flipped Vertical pHash hashes:\n",
      "Average Flipped Vertical pHash Similarity: 0.8792585059171598\n",
      "Comparing original and Flipped Vertical wHash hashes:\n",
      "Average Flipped Vertical wHash Similarity: 0.9097050665680473\n",
      "Comparing original and Flipped Vertical aHash hashes:\n",
      "Average Flipped Vertical aHash Similarity: 0.9124121671597634\n",
      "Comparing original and Flipped Vertical dHash hashes:\n",
      "Average Flipped Vertical dHash Similarity: 0.9159763313609467\n",
      "Comparing original and Flipped Vertical KL Hash hashes:\n",
      "Average Flipped Vertical KL Hash Similarity: 0.8656120562130177\n",
      "Applying Translated transformation...\n",
      "Comparing original and Translated pHash hashes:\n",
      "Average Translated pHash Similarity: 0.8927200443786982\n",
      "Comparing original and Translated wHash hashes:\n",
      "Average Translated wHash Similarity: 0.9329992603550296\n",
      "Comparing original and Translated aHash hashes:\n",
      "Average Translated aHash Similarity: 0.9341494082840237\n",
      "Comparing original and Translated dHash hashes:\n",
      "Average Translated dHash Similarity: 0.921143676035503\n",
      "Comparing original and Translated KL Hash hashes:\n",
      "Average Translated KL Hash Similarity: 0.8837148668639053\n",
      "Applying Zoomed transformation...\n",
      "Comparing original and Zoomed pHash hashes:\n",
      "Average Zoomed pHash Similarity: 0.8910059171597633\n",
      "Comparing original and Zoomed wHash hashes:\n",
      "Average Zoomed wHash Similarity: 0.9241346153846154\n",
      "Comparing original and Zoomed aHash hashes:\n",
      "Average Zoomed aHash Similarity: 0.9292557322485208\n",
      "Comparing original and Zoomed dHash hashes:\n",
      "Average Zoomed dHash Similarity: 0.8980075813609467\n",
      "Comparing original and Zoomed KL Hash hashes:\n",
      "Average Zoomed KL Hash Similarity: 0.8912851331360947\n",
      "Applying Affine Transformed transformation...\n",
      "Comparing original and Affine Transformed pHash hashes:\n",
      "Average Affine Transformed pHash Similarity: 0.894119822485207\n",
      "Comparing original and Affine Transformed wHash hashes:\n",
      "Average Affine Transformed wHash Similarity: 0.9206915680473373\n",
      "Comparing original and Affine Transformed aHash hashes:\n",
      "Average Affine Transformed aHash Similarity: 0.924166974852071\n",
      "Comparing original and Affine Transformed dHash hashes:\n",
      "Average Affine Transformed dHash Similarity: 0.9024648668639054\n",
      "Comparing original and Affine Transformed KL Hash hashes:\n",
      "Average Affine Transformed KL Hash Similarity: 0.8816401627218935\n",
      "Applying Perspective Transformed transformation...\n",
      "Comparing original and Perspective Transformed pHash hashes:\n",
      "Average Perspective Transformed pHash Similarity: 0.8900795118343195\n",
      "Comparing original and Perspective Transformed wHash hashes:\n",
      "Average Perspective Transformed wHash Similarity: 0.9077459319526627\n",
      "Comparing original and Perspective Transformed aHash hashes:\n",
      "Average Perspective Transformed aHash Similarity: 0.9114441568047337\n",
      "Comparing original and Perspective Transformed dHash hashes:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Perspective Transformed dHash Similarity: 0.9067464866863906\n",
      "Comparing original and Perspective Transformed KL Hash hashes:\n",
      "Average Perspective Transformed KL Hash Similarity: 0.8805306952662721\n",
      "Applying Frame Dropped transformation...\n",
      "Comparing original and Frame Dropped pHash hashes:\n",
      "Warning: The number of hashes in the original and modified videos do not match.\n",
      "Could not compute similarity scores for Frame Dropped using pHash.\n",
      "Comparing original and Frame Dropped wHash hashes:\n",
      "Warning: The number of hashes in the original and modified videos do not match.\n",
      "Could not compute similarity scores for Frame Dropped using wHash.\n",
      "Comparing original and Frame Dropped aHash hashes:\n",
      "Warning: The number of hashes in the original and modified videos do not match.\n",
      "Could not compute similarity scores for Frame Dropped using aHash.\n",
      "Comparing original and Frame Dropped dHash hashes:\n",
      "Warning: The number of hashes in the original and modified videos do not match.\n",
      "Could not compute similarity scores for Frame Dropped using dHash.\n",
      "Comparing original and Frame Dropped KL Hash hashes:\n",
      "Warning: The number of hashes in the original and modified videos do not match.\n",
      "Could not compute similarity scores for Frame Dropped using KL Hash.\n",
      "Applying Frame Rate Converted transformation...\n",
      "Comparing original and Frame Rate Converted pHash hashes:\n",
      "Average Frame Rate Converted pHash Similarity: 0.9987925295857988\n",
      "Comparing original and Frame Rate Converted wHash hashes:\n",
      "Average Frame Rate Converted wHash Similarity: 0.9972152366863906\n",
      "Comparing original and Frame Rate Converted aHash hashes:\n",
      "Average Frame Rate Converted aHash Similarity: 0.999113350591716\n",
      "Comparing original and Frame Rate Converted dHash hashes:\n",
      "Average Frame Rate Converted dHash Similarity: 0.9984448964497041\n",
      "Comparing original and Frame Rate Converted KL Hash hashes:\n",
      "Average Frame Rate Converted KL Hash Similarity: 0.983855399408284\n",
      "Applying Slowed Down transformation...\n",
      "Comparing original and Slowed Down pHash hashes:\n",
      "Average Slowed Down pHash Similarity: 0.9987925295857988\n",
      "Comparing original and Slowed Down wHash hashes:\n",
      "Average Slowed Down wHash Similarity: 0.9972152366863906\n",
      "Comparing original and Slowed Down aHash hashes:\n",
      "Average Slowed Down aHash Similarity: 0.999113350591716\n",
      "Comparing original and Slowed Down dHash hashes:\n",
      "Average Slowed Down dHash Similarity: 0.9984448964497041\n",
      "Comparing original and Slowed Down KL Hash hashes:\n",
      "Average Slowed Down KL Hash Similarity: 0.983855399408284\n",
      "Applying Looped transformation...\n",
      "Comparing original and Looped pHash hashes:\n",
      "Warning: The number of hashes in the original and modified videos do not match.\n",
      "Could not compute similarity scores for Looped using pHash.\n",
      "Comparing original and Looped wHash hashes:\n",
      "Warning: The number of hashes in the original and modified videos do not match.\n",
      "Could not compute similarity scores for Looped using wHash.\n",
      "Comparing original and Looped aHash hashes:\n",
      "Warning: The number of hashes in the original and modified videos do not match.\n",
      "Could not compute similarity scores for Looped using aHash.\n",
      "Comparing original and Looped dHash hashes:\n",
      "Warning: The number of hashes in the original and modified videos do not match.\n",
      "Could not compute similarity scores for Looped using dHash.\n",
      "Comparing original and Looped KL Hash hashes:\n",
      "Warning: The number of hashes in the original and modified videos do not match.\n",
      "Could not compute similarity scores for Looped using KL Hash.\n"
     ]
    }
   ],
   "source": [
    "# Apply transformations and compute the hashes for each transformation\n",
    "for transformation, (func, output_path) in transformations.items():\n",
    "    print(f\"Applying {transformation} transformation...\")\n",
    "    if transformation in ['Rotated', 'Resized', 'Cropped', 'Translated', 'Zoomed', 'Affine Transformed', 'Perspective Transformed', 'Frame Dropped', 'Frame Rate Converted', 'Slowed Down', 'Looped']:\n",
    "        # These need specific handling as they are video level transformations\n",
    "        func(video_path, output_path)\n",
    "    else:\n",
    "        # Frame-level transformations\n",
    "        process_and_save_video(video_path, output_path, func)\n",
    "\n",
    "    # Compute hashes for the transformed video\n",
    "    modified_hashes = {\n",
    "        'pHash': process_video_and_compute_hashes(output_path, phash),\n",
    "        'wHash': process_video_and_compute_hashes(output_path, whash),\n",
    "        'aHash': process_video_and_compute_hashes(output_path, ahash),\n",
    "        'dHash': process_video_and_compute_hashes(output_path, dhash),\n",
    "        'KL Hash': process_video_and_compute_hashes(output_path, kl_hash)\n",
    "    }\n",
    "\n",
    "    # Compare and compute similarity scores\n",
    "    for hash_type in original_hashes.keys():\n",
    "        print(f\"Comparing original and {transformation} {hash_type} hashes:\")\n",
    "        scores, avg_score = compute_similarity_scores(original_hashes[hash_type], modified_hashes[hash_type])\n",
    "        if scores:\n",
    "            #print(f\"{transformation} {hash_type} Similarity Scores:\", scores)\n",
    "            print(f\"Average {transformation} {hash_type} Similarity:\", avg_score)\n",
    "        else:\n",
    "            print(f\"Could not compute similarity scores for {transformation} using {hash_type}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
